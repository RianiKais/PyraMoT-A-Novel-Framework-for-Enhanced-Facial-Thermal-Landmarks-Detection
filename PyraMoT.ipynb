{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Z6FpDBP6dKT-"},"outputs":[],"source":["Results_path = \"Your_Results_path\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FSVk-xd2Avdo","scrolled":true},"outputs":[],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_iSCUWApdKUF"},"outputs":[],"source":["import tensorflow as tf\n","gpus = tf.config.experimental.list_physical_devices('GPU')\n","if gpus:\n","    try:\n","        # Currently, memory growth needs to be the same across GPUs\n","        for gpu in gpus:\n","            tf.config.experimental.set_memory_growth(gpu, True)\n","        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n","        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n","    except RuntimeError as e:\n","        # Memory growth must be set before GPUs have been initialized\n","        print(e)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sGONulmkAvdy"},"outputs":[],"source":["# import the necessary packages\n","from imutils import paths\n","import imutils\n","import json\n","import time\n","import cv2\n","import os\n","import math\n","import numpy as np\n","import pandas as pd\n","import PIL\n","from PIL import Image\n","import random\n","import h5py\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import MaxPooling2D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten, GlobalAveragePooling2D\n","from tensorflow.keras.layers import AveragePooling2D\n","from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n","from tensorflow.keras.layers import UpSampling2D\n","from tensorflow.keras.layers import Conv2D, Conv2DTranspose, Dropout, LeakyReLU, BatchNormalization, Input, Concatenate, Activation, concatenate, Input\n","from keras.initializers import RandomNormal\n","from tensorflow.keras.models import Model, load_model, Sequential\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.applications import MobileNetV2\n","from tensorflow.keras.utils import plot_model"]},{"cell_type":"markdown","metadata":{"id":"AJx0GYxhAvd0"},"source":["### Loading SpeakingFaces dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3qtfowAgAvd8"},"outputs":[],"source":["# function to correct landmarks' order after mirroring\n","\n","def correct_landmarks_order(pts_mirr):\n","    # pts_mirr - list of landmarks for one face\n","\n","\tpts_mirr_c = []\n","\n","\t# chin\n","\tpts_mirr_c.append(pts_mirr[16])\n","\tpts_mirr_c.append(pts_mirr[15])\n","\tpts_mirr_c.append(pts_mirr[14])\n","\tpts_mirr_c.append(pts_mirr[13])\n","\tpts_mirr_c.append(pts_mirr[12])\n","\tpts_mirr_c.append(pts_mirr[11])\n","\tpts_mirr_c.append(pts_mirr[10])\n","\tpts_mirr_c.append(pts_mirr[9])\n","\tpts_mirr_c.append(pts_mirr[8])\n","\tpts_mirr_c.append(pts_mirr[7])\n","\tpts_mirr_c.append(pts_mirr[6])\n","\tpts_mirr_c.append(pts_mirr[5])\n","\tpts_mirr_c.append(pts_mirr[4])\n","\tpts_mirr_c.append(pts_mirr[3])\n","\tpts_mirr_c.append(pts_mirr[2])\n","\tpts_mirr_c.append(pts_mirr[1])\n","\tpts_mirr_c.append(pts_mirr[0])\n","\n","\t# left eyebrow\n","\tpts_mirr_c.append(pts_mirr[26])\n","\tpts_mirr_c.append(pts_mirr[25])\n","\tpts_mirr_c.append(pts_mirr[24])\n","\tpts_mirr_c.append(pts_mirr[23])\n","\tpts_mirr_c.append(pts_mirr[22])\n","\n","\t# right eyebrow\n","\tpts_mirr_c.append(pts_mirr[21])\n","\tpts_mirr_c.append(pts_mirr[20])\n","\tpts_mirr_c.append(pts_mirr[19])\n","\tpts_mirr_c.append(pts_mirr[18])\n","\tpts_mirr_c.append(pts_mirr[17])\n","\n","\t# nose bridge\n","\tpts_mirr_c.append(pts_mirr[27])\n","\tpts_mirr_c.append(pts_mirr[28])\n","\tpts_mirr_c.append(pts_mirr[29])\n","\tpts_mirr_c.append(pts_mirr[30])\n","\n","\t# nose tip\n","\tpts_mirr_c.append(pts_mirr[35])\n","\tpts_mirr_c.append(pts_mirr[34])\n","\tpts_mirr_c.append(pts_mirr[33])\n","\tpts_mirr_c.append(pts_mirr[32])\n","\tpts_mirr_c.append(pts_mirr[31])\n","\n","\t# left eye\n","\tpts_mirr_c.append(pts_mirr[45])\n","\tpts_mirr_c.append(pts_mirr[44])\n","\tpts_mirr_c.append(pts_mirr[43])\n","\tpts_mirr_c.append(pts_mirr[42])\n","\tpts_mirr_c.append(pts_mirr[47])\n","\tpts_mirr_c.append(pts_mirr[46])\n","\n","\t# right eye\n","\tpts_mirr_c.append(pts_mirr[39])\n","\tpts_mirr_c.append(pts_mirr[38])\n","\tpts_mirr_c.append(pts_mirr[37])\n","\tpts_mirr_c.append(pts_mirr[36])\n","\tpts_mirr_c.append(pts_mirr[41])\n","\tpts_mirr_c.append(pts_mirr[40])\n","\n","\t# lips\n","\tpts_mirr_c.append(pts_mirr[50])\n","\tpts_mirr_c.append(pts_mirr[49])\n","\tpts_mirr_c.append(pts_mirr[48])\n","\tpts_mirr_c.append(pts_mirr[51])\n","\tpts_mirr_c.append(pts_mirr[52])\n","\tpts_mirr_c.append(pts_mirr[53])\n","\n","\treturn pts_mirr_c"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"axZpxoW6dKUO"},"outputs":[],"source":["# path to the dataset\n","Im_type = 'gray'\n","datasetPath = './D5050/Images_'+ Im_type +'/'\n","\n","\n","\n","# original image size and intended image size\n","#H = 348\n","#W = 464\n","#H = 768\n","#W = 1024\n","H = 512\n","W = 640\n","\n","h = 256\n","w = 256\n","\n","# number of facial landmarks\n","KEYPOINTS = 54\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dlQDTNEOdKUP"},"outputs":[],"source":["# function to import dataset\n","def import_data(t,s):\n","    # s - train / val / test\n","    # t- gray/iron/arrays\n","    # list to store imported data\n","    images = []\n","\n","    masks =[]\n","    annotations =[]\n","    #a,b,c,d=[],[],[],[]\n","    extn_map={\"arrays\":'.npy',\"gray\":'.jpg',\"iron\":'.png'}\n","    # extract paths to json files\n","    # we use grayscaled images for landmark prediction\n","    #jsonFolder = os.path.join(datasetPath, \"gray\", s, 'json')\n","    #jsonPaths = list(paths.list_files(jsonFolder, validExts=\"json\"))\n","    #jsonPaths = sorted(jsonPaths)\n","    #datesetPath='/thermal/MyDrive/dataset'\n","    labelsFolder=os.path.join(datasetPath,s)\n","    #labelsFolder='/thermal/MyDrive/dataset'\n","    txtPaths = list(paths.list_files(labelsFolder, validExts=\"txt\"))\n","    txtPaths = sorted(txtPaths)\n","\n","    # loop over the json files\n","    for ind, txtPath in enumerate(txtPaths, 1):\n","\n","        print(\"[INFO] Processing {} file ({}/{})\".format(txtPath.split(\"/\")[-1], ind, len(txtPaths)))\n","\n","        # opening the text file\n","        f = open(txtPath,)\n","        f=f.readlines()\n","\n","        # loading the image and converting it to grayscale\n","        if t==\"gray\":\n","          imagePath = txtPath.replace('labels','images')\n","          imagePath = imagePath.replace('.txt', '.jpg')\n","          image = cv2.imread(imagePath)\n","          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        if t==\"iron\":\n","          imagePath = txtPath.replace('labels','images')\n","          imagePath = imagePath.replace('.txt', '.png')\n","          image = cv2.imread(imagePath)\n","          image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        if t==\"arrays\":\n","          imagePath = txtPath.replace('labels','images')\n","          imagePath = imagePath.replace('.txt', '.npy')\n","          image=np.load(imagePath)\n","          #image = cv2.imread(imagePath)\n","          #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # loading and processing the mask\n","        maskPath =imagePath.replace('images','masks_bb2')\n","        maskPath =maskPath.replace(extn_map[t],'.png')\n","        mask = cv2.imread(maskPath)\n","        mask = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n","        mask = mask.astype('float32')\n","        mask = mask / 255.0\n","        # mirrored mask\n","        mask_mirr = cv2.flip(mask, flipCode=1)\n","\n","        # iterating through the shapes\n","        landmarks = []\n","\n","\n","        land=[]\n","        for point in f:\n","            point=point.split(' ')\n","            x=point[1]\n","            y=point[2]\n","            (x,y)=(W*float(x),H*float(y))\n","\n","            land.append([y, x])\n","        land = np.array(land)\n","\n","        #land = np.array(f['landmarks']['points'])\n","\n","        # extracting bounding box by padding landmarks\n","        ys = int(np.min(land[:,0]))-40\n","        ye = int(np.max(land[:,0]))+5\n","        xs = int(np.min(land[:,1]))-5\n","        xe = int(np.max(land[:,1]))+5\n","\n","        (xs, ys, xe, ye) = (int(xs), int(ys), int(xe), int(ye))\n","\n","        # crop image to bounding box, resize, normalize\n","        crop_image = image[ys:ye+1, xs:xe+1]\n","        crop_image = cv2.resize(crop_image, (w, h) )\n","        crop_image = crop_image.astype('float32')\n","        crop_image = crop_image / 255.0\n","\n","        # mirror the processed image\n","        crop_image_flip = cv2.flip(crop_image, flipCode=1)\n","\n","        for point in f:\n","            point=point.split(' ')\n","            x=point[1]\n","            y=point[2]\n","            (x,y)=(float(x)*W,float(y)*H)\n","\n","\n","\n","            #adjust landmarks to bounding box and normalize\n","            (crop_x, crop_y) = (x-xs, y-ys)\n","            (crop_x, crop_y) = (crop_x / (xe-xs), crop_y / (ye-ys))\n","\n","            landmarks.append([crop_y, crop_x])\n","\n","\n","\n","\n","        landmarks = np.array(landmarks)\n","\n","        # mirror the landmarks\n","        landmarks_mirr = landmarks.copy()\n","        landmarks_mirr[:,1] = 1 - landmarks_mirr[:,1]\n","        landmarks_mirr = correct_landmarks_order(landmarks_mirr.tolist())\n","\n","        # flatten the landmarks\n","        landmarks = landmarks.flatten()\n","        landmarks_mirr = np.array(landmarks_mirr).flatten()\n","\n","        # store imported and processed data\n","        images.append(crop_image)\n","        annotations.append(landmarks)\n","        masks.append(mask)\n","\n","        images.append(crop_image_flip)\n","        annotations.append(landmarks_mirr)\n","        masks.append(mask_mirr)\n","\n","\n","    # converting to numpy arrays\n","    # expanding image dimensions from (N, h, w) to (N, h, w, 1)\n","    images = np.expand_dims(np.array(images), axis = 3)\n","    masks = np.expand_dims(np.array(masks), axis = 3)\n","    annotations = np.array(annotations)\n","\n","    return images, masks, annotations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3VgwkLWLdKUR"},"outputs":[],"source":["#Preparing Training set\n","img_train,bmask_train,l_train=import_data(Im_type,'train')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h6KfS7NTdKUS"},"outputs":[],"source":["#Preparing val set\n","img_val,bmask_val,l_val=import_data(Im_type,'val')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_d_6NNq-dKUT"},"outputs":[],"source":["#Preparing Test set\n","img_test,bmask_test,l_test=import_data(Im_type,'test')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jXYWhowMAveC"},"outputs":[],"source":["# sanity check\n","print(img_train.shape)\n","print(img_val.shape)\n","print(img_test.shape)\n","print(l_train.shape)\n","print(l_val.shape)\n","print(l_test.shape)\n","print(bmask_train.shape)\n","print(bmask_val.shape)\n","print(bmask_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d8vuDKfaAveD"},"outputs":[],"source":["# visualize to check if images were correctly uploaded\n","\n","def visualize(image, landmarks, mask):\n","\n","    fig, axs = plt.subplots(1, 2, figsize=(10,5))\n","\n","    axs[0].imshow(image[:,:,0], cmap='gray')\n","    axs[1].imshow(mask[:,:,0], cmap='gray')\n","\n","    keys = landmarks.copy().reshape(KEYPOINTS,2)\n","\n","    axs[0].plot(keys[:,1]*w, keys[:,0]*h, 'gD', markersize=3)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsHeuGlHAveE","scrolled":true},"outputs":[],"source":["for i in range(50):\n","    visualize(img_train[i], l_train[i], bmask_train[i])"]},{"cell_type":"markdown","metadata":{"id":"yhQYKiAJAveG"},"source":["### Loading RWTH-Aachen dataset (additional test set)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7W4TV5N9AveG"},"outputs":[],"source":["# paths to the dataset\n","jsonFolder = \"./rwth_aachen/FaceDB_PNG_2935/\"\n","jsonPaths = list(paths.list_files(jsonFolder, validExts=\"ljson\"))\n","jsonPaths = sorted(jsonPaths)\n","\n","# original image size\n","H = 768\n","W = 1024\n","\n","# list to store read information\n","l_aachen = []\n","img_aachen = []"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5Q_nJ3FNAveH"},"outputs":[],"source":["# loop over the json files\n","for ind, jsonPath in enumerate(jsonPaths, 1):\n","\n","    print(\"[INFO] Processing {} file ({}/{})\".format(jsonPath.split(\"/\")[-1], ind, len(jsonPaths)))\n","\n","    # opening the json file\n","    f = open(jsonPath,)\n","\n","    # returns the json object as a dictionary\n","    data = json.load(f)\n","\n","    # extracting filename\n","    filename = jsonPath.split(\"/\")[-1]\n","    filename = filename.split(\".ljson\")[0]\n","    filename_img = os.path.join(jsonFolder, \"{}.png\".format(filename))\n","\n","    # subject id\n","    subj = int(filename.split('sub0')[1].split('_')[0])\n","\n","    # reading images\n","    image = cv2.imread(filename_img)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","    # reading landmarks\n","    land = np.array(data['landmarks']['points'])\n","\n","    # extracting bounding box by padding landmarks\n","    ys = int(np.min(land[:,0]))-40\n","    ye = int(np.max(land[:,0]))+5\n","    xs = int(np.min(land[:,1]))-5\n","    xe = int(np.max(land[:,1]))+5\n","\n","    # normalize landmarks\n","    land[:,0] = (land[:,0] - ys) / (ye - ys)\n","    land[:,1] = (land[:,1] - xs) / (xe - xs)\n","\n","    # downsample landmarks\n","    landmarks = np.zeros((54, 2))\n","    landmarks[:49,:] = land[:49,:]\n","    landmarks[49,:] = land[51,:]\n","    landmarks[50,:] = land[54,:]\n","    landmarks[51,:] = land[57,:]\n","    landmarks[52,:] = land[62,:]\n","    landmarks[53,:] = land[66,:]\n","\n","    landmarks = landmarks.flatten()\n","\n","    # crop image to bounding box, resize, normalize\n","    crop_image = image[ys:ye+1, xs:xe+1]\n","    crop_image = cv2.resize(crop_image, (w, h) )\n","    crop_image = crop_image.astype('float32')\n","    crop_image = crop_image / 255.0\n","\n","    img_aachen.append(crop_image)\n","    l_aachen.append(landmarks)\n","\n","    # closing file\n","    f.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9JJ_7pdiAveI"},"outputs":[],"source":["# expand dimensions so that images have one channel\n","img_aachen = np.expand_dims(np.array(img_aachen), axis = 3)\n","l_aachen = np.array(l_aachen)\n","\n","# sanity check\n","print(img_aachen.shape)\n","print(l_aachen.shape)"]},{"cell_type":"markdown","metadata":{"id":"bgkIg5xZAveK"},"source":["### Model"]},{"cell_type":"markdown","metadata":{"id":"jojR2hWIdKUh"},"source":["p5 = Conv2D(256, (1, 1), activation='relu', padding='same')(conv5_)\n","    p4 = concatenate([UpSampling2D(size=(4, 4))(p5), conv4_])\n","    p3 = concatenate([UpSampling2D(size=(2, 2))(p4), conv3_])\n","\n","    # Lateral connections\n","    p3 = Conv2D(256, (1, 1), activation='relu', padding='same')(p3)\n","    p4 = Conv2D(256, (1, 1), activation='relu', padding='same')(p4)\n","    p5 = Conv2D(256, (1, 1), activation='relu', padding='same')(p5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rU2ZVG_BdKUi"},"outputs":[],"source":["\n","def create_model(image_shape):\n","    # Prepare the kernel initializer values\n","    weight_init = RandomNormal(stddev=0.02)\n","\n","    # Prepare the Input layer\n","    net_input = Input((image_shape))\n","\n","    # Download mobile net, and use it as the base.\n","    mobile_net_base = MobileNetV2(\n","        include_top=False,\n","        input_shape=(224, 224, 3),\n","        weights='imagenet'\n","    )\n","    resized_input = tf.image.resize(net_input, (224, 224))\n","    expand_channels = Conv2D(3, (1, 1), padding='same', use_bias=False,\n","                             kernel_initializer=RandomNormal(stddev=0.02))(resized_input)\n","    mobilenet = mobile_net_base(expand_channels)\n","\n","\n","    # Encoder block #\n","    # 224x224\n","    conv1 = Conv2D(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(net_input)\n","    conv1 = LeakyReLU(alpha=0.2)(conv1)\n","\n","    # 112x112\n","    conv2 = Conv2D(128, (3, 3), strides=(1, 1), padding='same', kernel_initializer=weight_init)(conv1)\n","    conv2 = LeakyReLU(alpha=0.2)(conv2)\n","\n","    # 112x112\n","    conv3 = Conv2D(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(conv2)\n","    conv3 =  Activation('relu')(conv3)\n","\n","    # 56x56\n","    conv4 = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(conv3)\n","    conv4 = Activation('relu')(conv4)\n","\n","    # 28x28\n","    conv4_ = Conv2D(256, (3, 3), strides=(1, 1), padding='same', kernel_initializer=weight_init)(conv4)\n","    conv4_ = Activation('relu')(conv4_)\n","\n","    # 28x28\n","    conv5 = Conv2D(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(conv4_)\n","    conv5 = Activation('relu')(conv5)\n","\n","\n","    # 14x14\n","    conv5_ = Conv2D(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(conv5)\n","    conv5_ = Activation('relu')(conv5_)\n","\n","    #7x7\n","\n","    #Pyramid\n","    p5 = Conv2D(256, (1, 1), activation='relu', padding='same')(conv5_)\n","    p4 = concatenate([UpSampling2D(size=(2, 2))(p5), conv5 ])\n","    p3 = concatenate([UpSampling2D(size=(2, 2))(p4), conv4_ ])\n","\n","    # Lateral connections\n","    p3 = Conv2D(256, (1, 1), activation='relu', padding='same')(p3)\n","    p4 = Conv2D(256, (1, 1), activation='relu', padding='same')(p4)\n","    p5 = Conv2D(256, (1, 1), activation='relu', padding='same')(p5)\n","\n","\n","\n","    mobilenet = tf.image.resize(mobilenet, (8, 8))\n","\n","    # Fusion layer - Connects MobileNet with our encoder\n","    fusion = concatenate([mobilenet, p5])\n","    #fusion = Conv2D(512, (1, 1), padding='same', kernel_initializer=weight_init)(conc)\n","    #fusion = Activation('relu')(fusion)\n","\n","\n","\n","\n","    # Decoder block #\n","    # 7x7\n","    decoder = Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(fusion)\n","    decoder = Activation('relu')(decoder)\n","    decoder = Dropout(0.25)(decoder)\n","\n","\n","    fusion2 = concatenate([decoder, p4])\n","\n","    # 14x14\n","    decoder = Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(fusion2)\n","    decoder = Activation('relu')(decoder)\n","    decoder = Dropout(0.25)(decoder)\n","\n","\n","    fusion3 = concatenate([decoder, p3])\n","\n","    # 28x28\n","    decoder = Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(fusion3)\n","    decoder = Activation('relu')(decoder)\n","    decoder = Dropout(0.25)(decoder)\n","\n","    # 56x56\n","    decoder = Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(decoder)\n","    decoder = Activation('relu')(decoder)\n","    decoder = Dropout(0.25)(decoder)\n","\n","    # 112x112\n","    decoder = Conv2DTranspose(64, (3, 3), strides=(1, 1), padding='same', kernel_initializer=weight_init)(decoder)\n","    decoder = Activation('relu')(decoder)\n","\n","    # 112x112\n","    decoder = Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', kernel_initializer=weight_init)(decoder)\n","    decoder = Activation('relu')(decoder)\n","\n","    # 224x224\n","    # Output layer, with 1 channel (assuming grayscale output)\n","    output_layer = Conv2D(1, (1, 1), activation='tanh')(decoder)\n","\n","    model = Model(net_input, output_layer)\n","\n","    return model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6XyPkJgAveN","outputId":"d1758019-3a20-4a63-fa19-5a385c3373fd"},"outputs":[{"name":"stdout","output_type":"stream","text":[" conv2d_9 (Conv2D)              (None, 32, 32, 256)  262400      ['concatenate_1[0][0]']          \n","                                                                                                  \n"," concatenate_4 (Concatenate)    (None, 32, 32, 512)  0           ['dropout_1[0][0]',              \n","                                                                  'conv2d_9[0][0]']               \n","                                                                                                  \n"," conv2d_transpose_2 (Conv2DTran  (None, 64, 64, 128)  589952     ['concatenate_4[0][0]']          \n"," spose)                                                                                           \n","                                                                                                  \n"," activation_7 (Activation)      (None, 64, 64, 128)  0           ['conv2d_transpose_2[0][0]']     \n","                                                                                                  \n"," dropout_2 (Dropout)            (None, 64, 64, 128)  0           ['activation_7[0][0]']           \n","                                                                                                  \n"," conv2d_transpose_3 (Conv2DTran  (None, 128, 128, 64  73792      ['dropout_2[0][0]']              \n"," spose)                         )                                                                 \n","                                                                                                  \n"," activation_8 (Activation)      (None, 128, 128, 64  0           ['conv2d_transpose_3[0][0]']     \n","                                )                                                                 \n","                                                                                                  \n"," dropout_3 (Dropout)            (None, 128, 128, 64  0           ['activation_8[0][0]']           \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_4 (Conv2DTran  (None, 128, 128, 64  36928      ['dropout_3[0][0]']              \n"," spose)                         )                                                                 \n","                                                                                                  \n"," activation_9 (Activation)      (None, 128, 128, 64  0           ['conv2d_transpose_4[0][0]']     \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_transpose_5 (Conv2DTran  (None, 256, 256, 32  18464      ['activation_9[0][0]']           \n"," spose)                         )                                                                 \n","                                                                                                  \n"," activation_10 (Activation)     (None, 256, 256, 32  0           ['conv2d_transpose_5[0][0]']     \n","                                )                                                                 \n","                                                                                                  \n"," conv2d_12 (Conv2D)             (None, 256, 256, 1)  33          ['activation_10[0][0]']          \n","                                                                                                  \n","==================================================================================================\n","Total params: 15,883,524\n","Trainable params: 15,849,412\n","Non-trainable params: 34,112\n","__________________________________________________________________________________________________\n"]}],"source":["\n","# Assuming MK is created using the create_model function\n","MK = create_model((256,256,1))\n","MK.summary()"]},{"cell_type":"markdown","metadata":{"id":"7XFFq7xRAveO"},"source":["### First Stage: Pre-Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yscT384UAveP"},"outputs":[],"source":["# create checkpoint\n","checkpoint_dir = \"checkpoints-1\"\n","callback_checkpoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+\"/landmark\",\n","                                                      save_weights_only=True,\n","                                                      save_best_only=True,monitor='val_loss',\n","                                                      verbose=1)\n","\n","# initializing callback function\n","callbacks0 = [callback_checkpoint]\n","\n","if not tf.io.gfile.exists(checkpoint_dir):\n","    tf.io.gfile.mkdir(checkpoint_dir)\n","    print(\"Checkpoint directory created: {}\".format(checkpoint_dir))\n","\n","# if checkpoint exists, load the weights\n","latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n","\n","if latest_checkpoint:\n","    print(\"Checkpoint found: {}, restoring...\".format(latest_checkpoint))\n","    MK.load_weights(latest_checkpoint)\n","    print(\"Checkpoint restored: {}\".format(latest_checkpoint))\n","else:\n","    print(\"Checkpoint not found. Model weights will be initialized randomly.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzyHhQ4JAveQ"},"outputs":[],"source":["# learning rate scheduler\n","\n","def lr_schedule( epoch ):\n","\n","    lr = 5e-4\n","\n","    if epoch >= 10:\n","        lr = 1e-4\n","\n","    print(\"Learning rate: \", lr)\n","    return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cimKBXhFAveQ"},"outputs":[],"source":["# setting learning rate scheduler\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","# setting early stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","\n","callbacks0.append(lr_scheduler)\n","callbacks0.append(es)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xw8go4QOAveQ"},"outputs":[],"source":["# compile\n","MK.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr_schedule(0)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kjTsUv4fAveR","scrolled":true},"outputs":[],"source":["# train\n","\n","history = MK.fit(img_train, bmask_train, validation_data=(img_val, bmask_val), shuffle=True, batch_size=16, epochs=100, callbacks=callbacks0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpUyG6xvAveS"},"outputs":[],"source":["# plot loss vs epochs curve\n","\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.ylabel('Loss')\n","plt.xlabel('# epochs')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sSsDb3CqAveS"},"outputs":[],"source":["# visualizing predicted mask\n","\n","def visualize_mask_prediction(ind, images, masks_gt):\n","\n","    fig, axs = plt.subplots(1, 3, figsize=(15,5))\n","\n","    # predict mask on one image\n","    img = images[ind].copy()\n","    img = np.expand_dims(img, axis = 0)\n","    mask_pr = MK.predict(img)\n","\n","    # plot\n","    axs[0].imshow(img[0, :,:,0], cmap = 'gray')           # image\n","    axs[1].imshow(masks_gt[ind, :,:,0], cmap = 'gray')    # ground truth mask\n","    axs[2].imshow(mask_pr[0, :,:,0], cmap = 'gray')       # predicted mask\n","\n","    axs[0].axis('off')\n","    axs[1].axis('off')\n","    axs[2].axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sQAWM1FNAveT"},"outputs":[],"source":["visualize_mask_prediction(42, img_train, bmask_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yronx6LbAveT"},"outputs":[],"source":["visualize_mask_prediction(1028, img_test, bmask_test)"]},{"cell_type":"markdown","metadata":{"id":"F85Iw7X8AveT"},"source":["### Second Stage: Pre-Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"05WcUuuJdKUp"},"outputs":[],"source":["# fully connected layers\n","avg_pooling = AveragePooling2D(pool_size=(7, 7))(MK.output)\n","flat = Flatten() (avg_pooling)\n","\n","fc0 = Dense(2048, activation = 'relu') (flat)\n","dropout0 = Dropout(0.3)(fc0)\n","fc1 = Dense(512, activation = 'relu') (dropout0)\n","dropout1 = Dropout(0.3)(fc1)\n","fc2  = Dense(108, activation = 'sigmoid') (dropout1)\n","\n","# define full model\n","model_full = keras.Model(inputs=MK.input, outputs=fc2)\n","\n","# freeze layers\n","MK.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n3_s2tPQAveT"},"outputs":[],"source":["# to check whether layers are trainable or not\n","\n","for i,layer in enumerate(model_full.layers):\n","    print(i,layer.name,layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9gwHYg_aAveV"},"outputs":[],"source":["# Wing loss\n","\n","def wing_loss(land_gt, land_pred, w=10.0, epsilon=2.0):\n","\n","    with tf.name_scope('wing_loss'):\n","\n","        # compute constant C\n","        C = w * (1.0 - math.log(1.0 + w / epsilon))\n","\n","        x = land_gt - land_pred\n","        abs_x = tf.abs(x)\n","\n","        # if absolute x is smaller than w, then first equation\n","        # otherwise, second\n","        losses = tf.where(tf.greater(w, abs_x), w * tf.math.log(1.0 + abs_x / epsilon), abs_x - C)\n","        loss = tf.reduce_mean(losses)\n","\n","        return loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7VN7KqfYAveV"},"outputs":[],"source":["# create checkpoint\n","checkpoint_dir = \"checkpoints-2\"\n","\n","callback_checkpoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+\"/landmark\",\n","                                                      save_weights_only=True,\n","                                                      save_best_only=True,monitor='val_loss',\n","                                                      verbose=1)\n","\n","# initializing callback function\n","callbacks1 = [callback_checkpoint]\n","\n","if not tf.io.gfile.exists(checkpoint_dir):\n","    tf.io.gfile.mkdir(checkpoint_dir)\n","    print(\"Checkpoint directory created: {}\".format(checkpoint_dir))\n","\n","# if checkpoint exists, load the weights\n","latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n","if latest_checkpoint:\n","    print(\"Checkpoint found: {}, restoring...\".format(latest_checkpoint))\n","    MK.load_weights(latest_checkpoint)\n","    print(\"Checkpoint restored: {}\".format(latest_checkpoint))\n","else:\n","    print(\"Checkpoint not found. Model weights will be initialized randomly.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZEUT-XqhAveW"},"outputs":[],"source":["# learning rate scheduler\n","def lr_schedule( epoch ):\n","\n","    lr = 1e-3\n","\n","    if epoch >= 20:\n","        lr = 1e-4\n","\n","    print(\"Learning rate: \", lr)\n","    return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZzJOxDt2AveX"},"outputs":[],"source":["# setting learning rate scheduler\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","# setting early stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","\n","callbacks1.append(lr_scheduler)\n","callbacks1.append(es)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zvgFhoBQdKU4"},"outputs":[],"source":["\n","def anisotropic_loss(land_gt, land_pred, a=4.0, b=2.0):\n","\n","\n","    land_gt = tf.reshape(land_gt, (-1, land_gt.shape[1] // 2, 2))\n","    land_pred = tf.reshape(land_pred, (-1, land_pred.shape[1] // 2, 2))\n","\n","    # Compute tangent vectors ti at each point\n","    ti = (land_pred[:, 2:] - land_pred[:, :-2]) / tf.norm(land_pred[:, 2:] - land_pred[:, :-2], axis=-1, keepdims=True)\n","    ti = tf.concat([ti[:, :1], ti, ti[:, -1:]], axis=1)  # Extend ti for the endpoints\n","\n","    # Compute weight matrices Wi based on the tangent vectors\n","    Wi = 1 / a**2 * tf.einsum('bij,bik->bijk', ti, ti) + 1 / b**2 * (tf.eye(2) - tf.einsum('bij,bik->bijk', ti, ti))\n","\n","    # Compute the loss\n","    loss = tf.reduce_sum(tf.einsum('bij,bij->bi', land_gt - land_pred, tf.einsum('bijk,bij->bik', Wi, land_gt - land_pred)))\n","\n","    # Average the loss over the batch\n","    loss = tf.reduce_mean(loss)\n","\n","    return loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"egDjKnunAveX"},"outputs":[],"source":["# compile\n","model_full.compile(optimizer=keras.optimizers.Adam(lr_schedule(0)), loss=anisotropic_loss)# 'mean_squared_error')#wing_loss)#anisotropic_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iSQwK042AveY"},"outputs":[],"source":["# train\n","history2 = model_full.fit(img_train, l_train, validation_data=(img_val, l_val), batch_size=16, shuffle=True, epochs=100, callbacks=callbacks1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4ktfWyIAveY"},"outputs":[],"source":["# plot loss vs epochs curve\n","\n","plt.plot(history2.history['loss'])\n","plt.plot(history2.history['val_loss'])\n","plt.ylabel('Loss')\n","plt.xlabel('# epochs')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MekxAcmSAveY"},"outputs":[],"source":["# visualize prediction on single image\n","\n","def visualize_pred(ind, images, landmarks):\n","\n","    plt.figure(figsize=(5,5))\n","\n","    # load an image\n","    img = images[ind].copy()\n","    img = np.expand_dims(img, axis = 0)\n","    plt.imshow(img[0][:,:,0], cmap='gray')\n","\n","    land_pred = model_full.predict(img)\n","\n","    # ground truth landmarks\n","    keypoints = landmarks[ind].copy().reshape(KEYPOINTS,2)\n","    keypoints[:,0] = keypoints[:,0] * h\n","    keypoints[:,1] = keypoints[:,1] * w\n","    #plt.plot(keypoints[:,1], keypoints[:,0], 'go', markersize=3)\n","\n","    # predicted landmarks\n","    keypointsT = land_pred[0].copy().reshape(KEYPOINTS,2)\n","    keypointsT[:,0] = keypointsT[:,0] * h\n","    keypointsT[:,1] = keypointsT[:,1] * w\n","    plt.plot(keypointsT[:,1], keypointsT[:,0], 'ro', markersize=3)\n","\n","    plt.axis('off')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3aTiwcC-AveZ"},"outputs":[],"source":["visualize_pred(42, img_train, l_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3x05xN_FAveZ"},"outputs":[],"source":["visualize_pred(1028, img_test, l_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bom0WNHsAveZ"},"outputs":[],"source":["# visualize prediction on random ten images\n","\n","def visualize_pred_rand(images, landmarks, gt=True):\n","\n","    fig, axs = plt.subplots(2, 3, figsize=(10,6))\n","    plt.subplots_adjust(wspace=0, hspace=0.1)\n","\n","    # selecting 10 random images from set\n","    indexes = np.random.randint(0,images.shape[0],10)\n","    img = images[indexes]\n","    land = landmarks[indexes]\n","    land_pred = model_full.predict(img)\n","\n","    # iterate over images\n","    ind = 0\n","\n","    for i in range(2):\n","        for j in range(3):\n","\n","            # display image\n","            axs[i, j].imshow(img[ind][:,:,0], cmap='gray')\n","\n","            # display predicted landmarks\n","            keypointsT = land_pred[ind].copy().reshape(KEYPOINTS,2)\n","            keypointsT[:,0] = keypointsT[:,0] * h\n","            keypointsT[:,1] = keypointsT[:,1] * w\n","\n","            axs[i, j].plot(keypointsT[:,1], keypointsT[:,0], 'ro', markersize=2)\n","\n","            # if gt is true, display ground truth landmarks\n","            if gt:\n","                keypoints = land[ind].copy().reshape(KEYPOINTS,2)\n","                keypoints[:,0] = keypoints[:,0] * h\n","                keypoints[:,1] = keypoints[:,1] * w\n","                axs[i, j].plot(keypoints[:,1], keypoints[:,0], 'go', markersize=2)\n","\n","            # turn off axis display\n","            axs[i, j].axis('off')\n","\n","            ind += 1\n","\n","    # save figure\n","    plt.savefig(\"results.png\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZsaIdpa8Avea"},"outputs":[],"source":["visualize_pred_rand(img_test, l_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bb4q5FnmAvea"},"outputs":[],"source":["def NME(land, land_pred, split, folder_path):\n","    N = land.shape[0]\n","    l = land.reshape(land.shape[:-1] + (KEYPOINTS, 2))\n","    lt = land_pred.reshape(land_pred.shape[:-1] + (KEYPOINTS, 2))\n","\n","    # Error calculation\n","    nme = (np.sum(np.sqrt(np.sum((l - lt) ** 2, axis=2)), axis=1)\n","           / np.sqrt(np.sum((l[:, 45] - l[:, 36]) ** 2, axis=1))) / KEYPOINTS\n","\n","    # Average over the whole sample\n","    nme_avg = np.sum(nme) / N\n","\n","    sorted_nme = np.sort(nme)\n","    cumulative_errors = np.arange(1, N + 1) / N * 100\n","\n","    threshold = 0.1\n","    failure_count = np.sum(nme >= threshold)\n","    failure_count2 = np.sum(nme >= 0)\n","    failure_rate = (failure_count / N) * 100\n","\n","    # Create a folder if it doesn't exist\n","    result_folder = os.path.join(folder_path, split)\n","    os.makedirs(result_folder, exist_ok=True)\n","\n","    # Save results to a file\n","    results_file_path = os.path.join(result_folder, f'{split}_results.txt')\n","    with open(results_file_path, 'w') as f:\n","        f.write(f'Average NME: {nme_avg}\\n')\n","        f.write(f'Failure Rate ({threshold * 100}% threshold): {failure_rate}%\\n')\n","        f.write(f'sorted_nme : {\", \".join(map(str, sorted_nme))}\\n')\n","        f.write(f'cumulative_errors : {\", \".join(map(str, cumulative_errors))}\\n')\n","\n","    # Plot and save the CED\n","    ced_plot_path = os.path.join(result_folder, f'{split}_ced_plot.png')\n","    plt.plot(sorted_nme, cumulative_errors)\n","    plt.xlabel('NME')\n","    plt.ylabel('Percentage of Samples (%)')\n","    plt.title(f'Cumulative Error Distribution (CED) - Threshold {threshold * 100}%')\n","    plt.grid(True)\n","    plt.savefig(ced_plot_path)\n","    plt.close()\n","\n","    return nme_avg, failure_rate, cumulative_errors, sorted_nme\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w2cQo8MuAveb"},"outputs":[],"source":["# predicting landmarks\n","l_test_pred = model_full.predict(img_test)\n","l_train_pred = model_full.predict(img_train)\n","l_val_pred = model_full.predict(img_val)\n","\n","# evaluating NME of predictions\n","print(\"Normalized Mean Error on training set: \", NME(l_train, l_train_pred,\"train1\", Results_path))\n","print(\"Normalized Mean Error on validation set: \", NME(l_val, l_val_pred,\"val1\", Results_path))\n","print(\"Normalized Mean Error on testing set: \", NME(l_test, l_test_pred,\"test1\", Results_path))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MLWylSeZdKU8"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"roiRphC-Aveb"},"source":["### Third Stage: Full Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TZgYMwFrAvec"},"outputs":[],"source":["# unfreezing the layers\n","MK.trainable = True\n","\n","for i,layer in enumerate(model_full.layers):\n","    print(i,layer.name,layer.trainable)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2CbFW_0HAvec"},"outputs":[],"source":["# create checkpoint\n","checkpoint_dir = \"checkpoints-3\"\n","\n","callback_checkpoint = keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir+\"/landmark\",\n","                                                      save_weights_only=True,\n","                                                      save_best_only=True,monitor='val_loss',\n","                                                      verbose=1)\n","\n","# initializing callback function\n","callbacks2 = [callback_checkpoint]\n","\n","if not tf.io.gfile.exists(checkpoint_dir):\n","    tf.io.gfile.mkdir(checkpoint_dir)\n","    print(\"Checkpoint directory created: {}\".format(checkpoint_dir))\n","\n","# if checkpoint exists, load the weights\n","latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n","\n","if latest_checkpoint:\n","    print(\"Checkpoint found: {}, restoring...\".format(latest_checkpoint))\n","    model_full.load_weights(latest_checkpoint)\n","    print(\"Checkpoint restored: {}\".format(latest_checkpoint))\n","else:\n","    print(\"Checkpoint not found. Model weights will be initialized randomly.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6m-qqECqAved"},"outputs":[],"source":["# learning rate scheduler\n","\n","def lr_schedule( epoch ):\n","\n","    lr = 1e-4\n","\n","    print(\"Learning rate: \", lr)\n","    return lr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N7SYOMwkAvee"},"outputs":[],"source":["# setting learning rate scheduler\n","lr_scheduler = LearningRateScheduler(lr_schedule)\n","\n","# setting early stopping\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n","\n","callbacks2.append(lr_scheduler)\n","callbacks2.append(es)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dAlWDhNbAvef"},"outputs":[],"source":["# compile\n","model_full.compile(optimizer = keras.optimizers.Adam(lr_schedule(0)), loss=anisotropic_loss)#'mean_squared_error')#wing_loss)#'mean_squared_error')#"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OHiQrFsDAvef"},"outputs":[],"source":["# train\n","history3 = model_full.fit(img_train, l_train, validation_data=(img_val, l_val), batch_size=16, shuffle=True, epochs=100, callbacks=callbacks2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4Al9-uS7Aveg"},"outputs":[],"source":["# plot loss vs epochs curve\n","\n","plt.plot(history3.history['loss'])\n","plt.plot(history3.history['val_loss'])\n","plt.ylabel('Loss')\n","plt.xlabel('# epochs')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()\n","\n","# load best weights from checkpoint"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mz-INALkAveg"},"outputs":[],"source":["# visualize ten random predictions from test set\n","\n","visualize_pred_rand(img_test, l_test, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdLwuHAmAveh"},"outputs":[],"source":["# visualize ten random predictions from RWTH-Aachen set\n","\n","visualize_pred_rand(img_aachen, l_aachen, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"smgnlMPhdKU_"},"outputs":[],"source":["visualize_pred(1020, img_test, l_test)"]},{"cell_type":"markdown","metadata":{"id":"4sRaqdf2Avei"},"source":["# calculate Mean Absolute Error\n","\n","def MAE(l, l_pred):\n","    \n","    mae = keras.losses.mean_absolute_error(l, l_pred)\n","    \n","    return np.mean(tf.Session().run(mae))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oZLKfHf6Avej"},"outputs":[],"source":["# calculate average time needed to predict landmarks on an image\n","\n","def inference_speed(images):\n","\n","    timings = []\n","\n","    # iterate over images\n","    for img in images:\n","\n","        img = np.expand_dims(img, axis = 0)\n","\n","        # record time\n","        start = time.time()\n","        preds = model_full.predict(img)\n","        end = time.time()\n","\n","        timings.append(end - start)\n","\n","    return np.average(timings)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nF9y9hVxAvej"},"outputs":[],"source":["# predicting landmarks\n","l_train_pred = model_full.predict(img_train)\n","l_val_pred = model_full.predict(img_val)\n","l_test_pred = model_full.predict(img_test)\n","l_test_aa_pred = model_full.predict(img_aachen)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2fL7LlfgAvej"},"outputs":[],"source":["# evaluating NME of predictions\n","# evaluating NME of predictions\n","print(\"Normalized Mean Error on training set: \", NME(l_train, l_train_pred,\"train2-2-1\", Results_path))\n","print(\"Normalized Mean Error on validation set: \", NME(l_val, l_val_pred,\"val2-2-1\", Results_path))\n","print(\"Normalized Mean Error on testing set: \", NME(l_test, l_test_pred,\"test2-2-1\", Results_path))\n","print(\"Normalized Mean Error on RWTH-Aachen: \", NME(l_aachen, l_test_aa_pred,\"test-aachen\", Results_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zzuWn4KsAvek"},"outputs":[],"source":["# inference speed\n","\n","print(\"Inference speed (average per image): \", inference_speed(img_test))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eYItVHLsAvek"},"outputs":[],"source":["# save weights\n","\n","model_full.save('model.h5')\n","print(\"Model size (KB): \", os.path.getsize('model.h5')/1000)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"45Fqia57dKVB"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":["bgkIg5xZAveK","7XFFq7xRAveO","F85Iw7X8AveT","roiRphC-Aveb"],"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}